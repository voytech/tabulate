= Tabulate - Reference Manual
:icons: font
:source-highlighter: highlight.js
by <wojmak@gmail.com>
:toc:

<<<
== Introduction

Exporting data to tabular file formats can be tedious and cumbersome - especially when business wants to have reports covering vast majority of system functionalities. Writing every exporting method using imperative API directly will soon make code verbose, error prone, hard to read and maintain. In such cases You want to hide implementation details using abstractions, but this is additional effort which is not desirable.

`Tabulate` tries to mitigate above problems with the help of `Kotlin`, its `type-safe DSL builders` and `extension functions`.

== Key concepts

=== Table model.

Table model defines how table will look like after data exporting. Its building blocks are:

- `column` - defines a single column in table,
- `row`  - may be user defined custom row or row that carries attributes for enriching existing record,
- `row cell` - defines cell within row. Cell is bound to a column via column id,
- `attribute` - introduces extensions to model.

Table model is internal concept and is not exposed to API consumers (only `attribute model` can be exposed as it is extensible and customizable). Table is always built using table builders as follows:

[source,kotlin,options="nowrap"]
----
productList.tabulate("file.xlsx") {
    name = "Table id" // <1>
    columns {   // <2>
        column("nr")
    }
    rows { // <3>
        row {  // first row when no index provided.
            cell("nr") { value = "Nr.:" } // <4>
        }
    }
}
----
<1> Firstly we give the table name. It can be used by exporter e.g., to add metadata like sheet name.
<2> Secondly we can provide column definitions. Column definition can be used to aggregate `ColumnAttributes` as well as `CellAttributes`. All attributes associated with particular column will apply to each cell in that column. Specifying column can also help to make table layout more readable.
<3> Next step is to define table rows. Here we can create additional custom rows (like header or footer) or enhance table look and feel with attributes associated with particular row.
<4> Each row can contain as many cells as many columns exist. Similarly to `row` - `cell` may be used to assign cell attributes with selected cell within row. You can also create cell with custom predefined or computed value.

Above, we have created table definition with single column and one row with single cell.
Cell binds to column by column identifier which in our case is simple text identifier.

This is very basic example. In order to gain more powers You will need to start using `attributes`.

`Attributes` are plain objects with inner properties that extends base model. Attributes can be mounted on multiple levels: _table_, _column_, _row_ and single _cell_ levels.

Example with attributes included:
[source,kotlin,options="nowrap"]
----
productList.tabulate("file.xlsx") {
    name = "Table id"
    attributes {
      filterAndSort {} // <1>
    }
    columns {
        column("nr") {
            attributes { width { px = 40 }} // <2>
        }
        column(Product::code) {
            attributes { width { auto = true}}
            attributes {
                text {
                    weight = DefaultWeightStyle.BOLD // <3>
                }
            }
        }
    }
    rows {
        row {  // first row when no explicit index provided.
              cell("nr") {
                value = "Nr.:"
                attributes {
                  text { // <4>
                    fontFamily = "Times New Roman"
                    fontColor = Colors.BLACK
                    fontSize = 12
                  }
                  background { color = Colors.BLUE }
                }
              }
        }
    }
}
----
<1> Top level table attribute `TableAttribute`.
<2> Column level `ColumnAttribute` that defines width of entire column
<3> Column level `CellAttribute` - an attribute applicable for every cell in particular column.
<4> Cell level attribute. This is the lowest possible level where we can mount custom attributes. Only `CellAttribute` can be used on that level.

=== Table DSL API - type-safe builders.

Kotlin type-safe builders fit well into describing table structure. They make source code look more concise and readable and developement becomes easier. At coding time, your IDE makes use of type-safety offered by builders and shows completion hints which elevates developer experience. Almost zero documentation is required to start. You can start playing with the API right now.

DSL functions by convention take `lambda with receivers` as arguments which abstract away internal API instantiation details from consumers. Within lambda you can call other API methods which in turn, can take downstream builders as arguments. This way - we can end up having multi-level DSL API structure, where each level is extensible via Kotlin extension functions. On each DSL level You are allowed to invoke receiver scope methods and access lexical scope variables which can lead to interesting results:
[source,kotlin,options="nowrap"]
----
    val additionalProducts = ... // <1>
    tabulate {
          name = "Products table"
          rows {
              header("Code", "Name", "Description", "Manufacturer") // <2>
              additionalProducts.forEach { // <3>
                  row {
                      cell { value = it.code }
                      cell { value = it.name }
                      cell { value = it.description }
                      cell { value = it.manufacturer }
                  }
              }
          }
    }.export("products.xlsx")
----
<1> Here we are using `additionalProducts` val which is collection of elements to be exported.
<2> After that, we define header as long as we know that our template doesn't mention it.
<3> Finally, we are iterating over collection elements to build static table model.

CAUTION: Although it is possible to build row definitions by iterating over collection directly, you should always prefer to use <<column_scoped_cell_value_providers>>. They are much faster and consume much less memory than approach shown in point number `3`.

As already said, it is possible to extend each DSL level by using extension functions on DSL API builder classes.

Take the example from previous section:
[source,kotlin,options="nowrap"]
----
    tabulate {
          rows {
              header("Code", "Name", "Description", "Manufacturer")
          }
    }.export("products.xlsx")
----
Function `.header` is implemented as follows:

[source,kotlin,options="nowrap"]
----
fun <T> RowsBuilderApi<T>.header(vararg names: String) =
    newRow(0) { // <1>
        cells {
            names.forEach {
                cell { value = it }
            }
        }
    }
----
<1> Calling `.newRow(0)` `RowsBuilderApi` method internally ensures that `.header` extension function always defines custom row at index `0`.

This way you can create various shortcuts and templates, making DSL vocabulary richer and more expressive.
It is worth mentioning that by using extension functions on DSL builders - scope becomes restricted by `DslMarker` annotation, so it is not possible to break table definition by calling methods from upstream builders.

=== Column-scoped cell value providers. [[column_scoped_cell_value_providers]]

Column API makes it possible to pass property getter reference as a column key.
This creates object property to column binding which is applied later at run time for cell value evaluation.
[source,kotlin,options="nowrap"]
----
productsRepository.loadProductsByDate(now()).tabulate("file/path/products.xlsx") {
            name = "Products table"
            columns {
                column(Product::code)
                column(Product::name)
                column(Product::description)
            }
        }
----
Property getter as column key kills two birds with one stone:

 - It allows to reference column later in cell builder,
 - it allows to extract collection element property value when row context is built for rendering.

Presence of <<column_scoped_cell_value_providers>> in table definition removes the requirement of explicit row definition.
It is enough to use `Product::code` getter reference as column key to determine value of each consecutive row cell.
You are still allowed to define new rows explicitly (through call `newRow([index value or <<row_index_predicates>>])`) or to
provide extensions to existing rows (through call `matching {  <<record_row_predicates>> } assign { ... }`).

=== Row predicates. [[row_predicates]]

==== Row index predicates. [[row_index_predicates]]

You have already seen how `.header` extension function is implemented. Internally it invokes `.newRow(0)` which requests rendering of a row at index `0`. What if You want to apply entire row definition for several indices ?
You may repeat `.newRow()` invocation as many times as required, but there is better option.
You can use row index predicate as follows:

[source,kotlin,options="nowrap"]
----
atIndex { gt(0) and lt(100) } newRow { // <1>
    cell { expression = RowCellExpression { "index : ${it.rowIndex.getIndex()}" } } // <2>
}
----
<1> We start the row line with method `atIndex { ... }` which takes row index predicate `gt(0) and lt(100)`. It literally says: 'Apply this row definition to all indices between index 0 and index 100'. Last 'keyword' sounds: `newRow` and delivers row definition from within curly braces.
<2> This line represents definition of a row which is about to be created for each matching index. It contains single cell with runtime expression evaluated at context rendering time.

There is also alternative notation used to achieve the same result:

[source,kotlin,options="nowrap"]
----
newRow({ gt(0) and lt(100) }) {
    cell { expression = RowCellExpression { "index : ${it.rowIndex.getIndex()}" } }
}
----

==== Record row predicates [[record_row_predicates]]

Record predicates differs from `row index predicates` in that they cannot be used to insert new custom rows. They can only enrich *existing* row, that is:

 - custom row that is created by `newRow` API method,
 - or a row that is derived from collection element (it is always produced from <<column_scoped_cell_value_providers>> column binding).

Record row predicates are always represented by a predicate function that checks if currently processed record or custom row meets specific conditions.

<<<
On API level we can define `row predicate` in two ways:

[source,kotlin]
----
// <1>
matching { <predicate> } assign {
  // row attributes, cells definition
}

// <2>
row({ <predicate> }) {
  // row attributes, cells definition
}
----
<1> First method seems to be closer to natural language but takes more space. Also it does not mention `row` so it may be not intuitive for some users.
<2> Second method uses DSL keyword **row** in first place which is desired, but as long as we associate predicate with row builder where both are lambdas, we are forced to use syntax like `({ ... })` which I personally do not like in Kotlin.

=== Mixing custom rows with collection elements.

`Tabulate` makes it possible to define table consisting only of custom rows that are known at build time.
It also allows You to generate table where each row is dynamically computed from collection of any type.
What is more, there is nothing that stops You from using both techniques for single table export:

[source,kotlin,options="nowrap"]
----
contracts.tabulate("contracts.xlsx") {
    name = "Active Contracts"
    // <1>
    columns {
        column(Contract::client)
        column(Contract::contractCode)
        column(Contract::contractLength)
        column(Contract::dateSigned)
    }
    rows {
        // <2>
        header {
            columnTitles(
                "Client",
                "Code",
                "Contract Length",
                "Date Signed",
            )
        }
    }
}
----
<1> In order to export collection of elements, all we need to do is do define column bindings with getter property references as identifiers. As long as there are no custom row defined in 'rows' section, all rows
in table will be rows originating from collection elements.
<2> If You declare custom row at specific index (or matching index predicate), then it will take precedence over dynamic rows generated from collection. So if You declare `header` row it will be the very first row in exported table, but when You write `newRow(2)` - this will create new custom row as third. Rows: 0 and 1 will be then reserved for dynamic data (collection elements) as long as there are no other custom rows declarations matching previous indices.

There are still cases where this flexibility is not enough. How can we define custom row that will be rendered after all dynamic data ? For that purpose we cannot just use index based predicate as long as we cannot tell the size of collection in advance. The solution for above is __multi-pass enabled `RowIndex` cursor__ used by context iterator. This `RowIndex` contains additional 'step' component which increments after there are no row index definitions for current pass. After 'step' is advanced, its local step-scope index is set to zero (this counter will increment per each row matching current pass). Global-scope row index is still maintained to support predicates using it.

Here is how You can add footer row:
[source,kotlin,options="nowrap"]
----
contracts.tabulate("contracts.xlsx") {
    name = "Active Contracts"
    columns {
        column(Contract::client)
        column(Contract::contractValue)
    }
    rows {
        header("Client","Contract Value")
        //<1>
        footer {
            cell { value = "Summary:"}
            cell { value = "=SUM" }
        }
    }
}
----
<1> In above example, `footer` is an extension function as `header`, but with one small difference:
[source,kotlin,options="nowrap"]
----
fun <T> RowsBuilderApi<T>.footer(block: RowBuilderApi<T>.() -> Unit) {
    newRow(0, AdditionalSteps.TRAILING_ROWS, block) //<1>
}
----
<1> In its implementation, it uses additional method argument: `AdditionalSteps.TRAILING_ROWS`. Internally this will create row index definition with index value / predicate, which is relative to TRAILING_ROWS pass. The sequence of additional passes is determined by enum ordinal values.

<<<
== Extension points.

I have put lots of effort to make **Tabulate** extensible. Currently, it is possible to:

- add user defined attributes,
- add custom renderers for already defined attributes,
- implement table export operations from scratch (e.g., html table, cli table, mock renderer for testing),
- extend DSL type-safe builder APIS on all possible levels.

=== Implementing table export operations from scratch.
In order to support new tabular file format you will have to:

- Create `RenderingContext` class. It represents internal state and low-level API to communicate with 3rd party library like Apache POI. Object of that class is passed to all table export operations as well as to all attribute rendering operations that are registered by `ServiceLoader` infrastructure. Such common denominator element is required to enable table modifications coming from within various render operations.
- Create `OutputBinding` class. It defines transformation of `RenderingContext` into different kind out outputs. By separating `OutputBinding` from `RenderingContext` we can enable multiple outputs for particular `RenderingContext` class dynamically.
- Define `ExportOperationsProvider` or `ExportOperationsConfiguringFactory` depending on your scenario. If You don't need to decouple attribute operations from table export operations (e.g., because supported format does not assumes attributes at all) You can implement `ExportOperationsProvider` interface and define all rendering logic in single class. For cases, where attributes needs to be rendered independently (e.g., because You want to support user-defined attributes) it is advised to extend `ExportOperationsConfiguringFactory`. For both scenarios You will have to create file `resource/META-INF/io.github.voytech.tabulate.template.spi.ExportOperationsProvider`, and put fully qualified class name of your custom factory in the first line. **This step is required by a template in order to resolve your extension at run-time**.

<<<
Below, basic CSV export operations implementation:

First step is to define `RenderingContext`:
[source,kotlin,options="nowrap"]
----
// <1>
open class CsvRenderingContext: RenderingContext {
    private lateinit var bufferedWriter: BufferedWriter
    private val line = StringBuilder()

    fun doBind(output: OutputStream) {
        bufferedWriter = output.bufferedWriter()
    }

    fun startRow() {
        line.clear()
    }

    private fun AttributedCell.getSeparatorCharacter(): String =
        attributes?.get(CellSeparatorCharacterAttribute::class.java)?.separator ?: ","

    fun <T> endRow(context: AttributedRowWithCells<T>) {
        val lastIndex = context.rowCellValues.size - 1
        context.rowCellValues.values.forEachIndexed { index, cell ->
            line.append(cell.value.value.toString())
            if (index < lastIndex) line.append(cell.getSeparatorCharacter())
        }
        bufferedWriter.write(line.toString())
        bufferedWriter.newLine()
    }

    fun finish() {
        bufferedWriter.close()
    }
}
----
<1> `CsvRenderingContext` implements `RenderingContext` marker interface and provides logic and state responsible for generating table in selected format. It is a common denominator used as argument of all export operation methods in order to share rendering state and allow interaction with it.

<<<
Then we need to create at least one `OutputBinding` in order to be able to flush results int output:
[source,kotlin,options="nowrap"]
----
class CsvOutputStreamOutputBinding : OutputStreamOutputBinding<CsvRenderingContext>() {

    override fun onBind(renderingContext: CsvRenderingContext, output: OutputStream) { // <1>
        renderingContext.doBind(output)
    }

    override fun flush(output: OutputStream) { // <2>
        renderingContext.finish()
        output.close()
    }
}
----
<1> The `.onBind` method is called internally by `TabulationTemplate` as soon as both: output and rendering context instances are available. It connects rendering context with particular output and allows implementing flush logic.
<2> The `.flush` dumps in-memory rendering context into given output.

<<<
Finally, we are implementing `ExportOperationsProvider` compatible with `RenderingContext` of choice:
[source,kotlin,options="nowrap"]
----
class CsvExportOperationsFactory: ExportOperationsProvider<CsvRenderingContext> {

    override fun getContextClass(): Class<CsvRenderingContext> = CsvRenderingContext::class.java // <1>

    override fun createRenderingContext() = CsvRenderingContext()  // <2>

    override fun supportsFormat(): TabulationFormat = format("csv") // <3>

    // <4>
    override fun createExportOperations(): AttributedContextExportOperations<CsvRenderingContext> = object :  AttributedContextExportOperations<CsvRenderingContext> {

        override fun beginRow(renderingContext: CsvRenderingContext, context: AttributedRow) {
            renderingContext.startRow()
        }

        override fun <T> endRow(renderingContext: CsvRenderingContext, context: AttributedRowWithCells<T>) {
            renderingContext.endRow(context)
        }
    }

    // <5>
    override fun createOutputBindings(): List<OutputBinding<CsvRenderingContext, *>> = listOf(CsvOutputStreamOutputBinding())

}
----
<1> Define the `RenderingContext` compatible with export operation provider,
<2> Create new `RenderingContext` instance. This instantiation always occurs at the very beginning,
<3> Declare `TabulationFormat`. It consists of file extension and provider identifier,
<4> This is the most important step. *Here we implement actual table rendering logic*,
<5> Finally - we need to provide list of supported outputs. Bare minimum should be at least `OutputStreamOutputBinding`.

<<<
If target tabular format supports styles, You may add support for rendering built-in attributes as follows:

[source,kotlin,options="nowrap"]
----
class ExampleExportOperationsConfiguringFactory : ExportOperationsConfiguringFactory<SomeRenderingContext>() {

  ..
  override fun getAttributeOperationsFactory(renderingContext: SomeRenderingContext): AttributeRenderOperationsFactory<SomeRenderingContext> =
      object: StandardAttributeRenderOperationsProvider<SomeRenderingContext>{
          override fun createTemplateFileRenderer(renderingContext: SomeRenderingContext): TableAttributeRenderOperation<TemplateFileAttribute> =
            TemplateFileAttributeRenderOperation(renderingContext)

          override fun createColumnWidthRenderer(renderingContext: SomeRenderingContext): ColumnAttributeRenderOperation<ColumnWidthAttribute> =
            ColumnWidthAttributeRenderOperation(renderingContext)

          override fun createRowHeightRenderer(renderingContext: SomeRenderingContext): RowAttributeRenderOperation<T, RowHeightAttribute> =
            RowHeightAttributeRenderOperation(renderingContext)

          override fun createCellTextStyleRenderer(renderingContext: SomeRenderingContext): CellAttributeRenderOperation<CellTextStylesAttribute> =
            CellTextStylesAttributeRenderOperation(renderingContext)

          override fun createCellBordersRenderer(renderingContext: SomeRenderingContext): CellAttributeRenderOperation<CellBordersAttribute> =
            CellBordersAttributeRenderOperation(renderingContext)

          override fun createCellAlignmentRenderer(renderingContext: SomeRenderingContext): CellAttributeRenderOperation<CellAlignmentAttribute> =
            CellAlignmentAttributeRenderOperation(renderingContext)

          override fun createCellBackgroundRenderer(renderingContext: SomeRenderingContext): CellAttributeRenderOperation<CellBackgroundAttribute> =
            CellBackgroundAttributeRenderOperation(renderingContext)
      })
}
----
Factory class `StandardAttributeRenderOperationsFactory` exposes API which assumes specific standard library attributes.
If your file format allow additional attributes which are not present in standard library (tabulate-core), you may use `AttributeRenderOperationsFactory` interface directly, or fill additional constructor properties on `StandardAttributeRenderOperationsFactory` as below:

[source,kotlin,options="nowrap"]
----
class ExampleExportOperationsConfiguringFactory<T> : ExportOperationsConfiguringFactory<T,SomeRenderingContext>() {

  ...
  override fun getAttributeOperationsFactory(renderingContext: SomeRenderingContext): AttributeRenderOperationsFactory<T> =
      StandardAttributeRenderOperationsFactory(renderingContext, object: StandardAttributeRenderOperationsProvider<SomeRenderingContext,T>{
          override fun createTemplateFileRenderer(renderingContext: SomeRenderingContext): TableAttributeRenderOperation<TemplateFileAttribute> = TemplateFileAttributeRenderOperation(renderingContext)
      },
        additionalCellAttributeRenderers = setOf( .. )
        additionalTableAttributeRenderers = setOf( .. )
      )
}
----

=== Registering new attribute types for existing export operations.
It is possible that you have requirements which cannot be achieved with standard set of attributes, and your code is in different compilation unit than specific table export operation implementation. Assume You want to use existing Apache POI excel table exporter, but there is lack of certain attribute support. In such situation - You can still register attribute by implementing another service provider interface - `AttributeRenderOperationsProvider`:

[source,kotlin,options="nowrap"]
----
class CustomAttributeRendersOperationsProvider : AttributeRenderOperationsProvider<ApachePoiRenderingContext> {

    override fun getContextClass() = ApachePoiRenderingContext::class.java

    override fun getAttributeOperationsFactory(renderingContext: ApachePoiRenderingContext): AttributeRenderOperationsFactory<ApachePoiRenderingContext> {
        return object : AttributeRenderOperationsFactory<ApachePoiRenderingContext> {
            override fun createCellAttributeRenderOperations(): Set<CellAttributeRenderOperation<out CellAttributeAlias>> =
                setOf(MarkerCellAttributeRenderOperation(renderingContext))
        }
    }
}
----

After creating factory - You need to implement particular attribute together with DSL API extension function and attribute render operation to instruct 3rd party Apache Poi API on how to proceed.

[source,kotlin,options="nowrap"]
----
data class MarkerCellAttribute(val text: String) : CellAttribute<MarkerCellAttribute>() {

    class Builder(var text: String = "") : CellAttributeBuilder<MarkerCellAttribute> {
        override fun build(): MarkerCellAttribute = MarkerCellAttribute(text)
    }
}

class SimpleMarkerCellAttributeRenderOperation  : CellAttributeRenderOperation<ApachePoiRenderingContext, SimpleTestCellAttribute>  {

    override fun attributeType(): Class<MarkerCellAttribute> = MarkerCellAttribute::class.java

    override fun renderAttribute(renderingContext: ApachePoiRenderingContext, context: RowCellContext, attribute: MarkerCellAttribute) {
        with(renderingContext.assertCell(context.getTableId(), context.rowIndex, context.columnIndex)) {
            this.setCellValue("${this.stringCellValue} [ ${attribute.label} ]")
        }
    }
}

fun <T> CellLevelAttributesBuilderApi<T>.label(block: MarkerCellAttribute.Builder.() -> Unit) =
    attribute(MarkerCellAttribute.Builder().apply(block))
----

Finally, You need to create file `resource/META-INF/io.github.voytech.tabulate.template.spi.AttributeRenderOperationsProvider`, and put fully qualified class name of our factory in it.

=== Extending Table DSL API

In the last section You saw how to define custom user attributes. The last step involves creating extension function on specific DSL attribute API. As DSL builder class name suggests (`CellLevelAttributesBuilderApi<T>`) this builder is part of a Cell DSL API only , which means that it won't be possible to add this attribute on row, column and table. You can leverage this behaviour for restricting say 'mounting points' of specific attributes. In order to enable cell attribute on all levels You will need to add more extension functions:

[source,kotlin,options="nowrap"]
----
fun <T> ColumnLevelAttributesBuilderApi<T>.label(block: MarkerCellAttribute.Builder.() -> Unit) =
    attribute(MarkerCellAttribute.Builder().apply(block).build())
fun <T> RowLevelAttributesBuilderApi<T>.label(block: MarkerCellAttribute.Builder.() -> Unit) =
  attribute(MarkerCellAttribute.Builder().apply(block).build())
fun <T> TableLevelAttributesBuilderApi<T>.label(block: MarkerCellAttribute.Builder.() -> Unit) =
  attribute(MarkerCellAttribute.Builder().apply(block).build())
----

Now You can call `label` on all DSL API levels in `attributes` scope like:

[source,kotlin,options="nowrap"]
----
productList.tabulate("file.xlsx") {
    name = "Table id"
    attributes {
      label { text = "TABLE" }
    }
    columns {
        column("nr") {
            attributes { label { text = "COLUMN" } }
            ..
        }
    }
    rows {
        row {
           attributes { label { text = "ROW" } }
           cell("nr") {
              value = "Nr.:"
              attributes {
                attributes { label { text = "CELL" } }
              }
           }
            ..
        }
    }
}
----
The result of above configuration will be as such:
- In the first row, cell at a column with id "nr" will end with `[ CELL ]`, and rest of cells will end with `[ ROW ]`,
- Remaining cells (starting from second row) in a column with id "nr" will end with `[ COLUMN ]`,
- All remaining cells will end with `[ TABLE ]`.

<<<
== Java interop - fluent builders Java API.
Old-fashioned Java fluent builder API is also supported. It is needless to say it looks much less attractive:

[source,java,options="nowrap"]
----
//<1>
FluentTableBuilderApi<Employee> employeeTable = TableBuilder<Employee>()
		.attribute(TemplateFileAttribute::builder, builder -> builder.setFileName("file.xlsx"))
        .attribute(ColumnWidthAttribute::builder, builder -> builder.setAuto(true))
		.columns()
            .column(of("id"),Employee::getId)
		    .column(of("firstName"),Employee::getFirstName)
		    .column(of("lastName"),Employee::getLastName)
		.rows()
		    .row(0)
		        .attribute(RowHeightAttribute::builder, builder -> builder.setPx(100))
		.build();
//<2>
List<Employee> employeeList = Collections.singletonList(new Employee("#00010", "Joshua", "Novak"));
new TabulationTemplate(format("xlsx")).export(employeeList, new FileOutputStream("employees.xlsx"), employeeTable);
----
<1> As a first step, You have to declare table definition using Java `FluentTableBuilderApi`
<2> Now You have to pass table definition into `TabulationTemplate` in order to export data with declared tabular layout.

<<<
== Library of attributes.

You may need attributes for various reasons - for styling, for formatting etc.

Currently, with `tabulate-core` and `tabulate-excel` modules, you will get following attributes included:

==== Table attributes
- `FilterAndSortAttribute` - enables filtering and sorting of Excel table,
- `TemplateFileAttribute` - allows performing template file interpolation with source data collection of items,

==== Column attributes
- `ColumnWidthAttribute` - sets the width of column (meaning all cells gathered under particular column will have same width),

==== Row attributes
- `RowHeightAttribute` - sets the height of row (meaning all cells gathered within particular row will have same height),

==== Cell attributes
- `CellTextStylesAttribute` - allows controlling general, text related style attributes,
- `CellBordersAttribute` - sets borders on selected cells,
- `CellBackgroundAttribute` - sets background color and fill,
- `CellAlignmentAttribute` - sets text vertical and horizontal alignment

Typical usage scenario for attributes:
[source,kotlin,options="nowrap"]
----
productsRepository.loadProductsByDate(now()).tabulate("product_with_styles.xlsx") {
    name = "Products table"
    columns {
        column(Product::code) {
            attributes(
                width { auto = true },
                text {
                    fontFamily = "Times New Roman"
                    fontColor = Colors.BLACK
                    fontSize = 12
                },
                background { color = Colors.BLUE }
            )
        }
        column(Product::distributionDate) {
            attributes(
                width { auto = true },
                dataFormat { value = "dd.mm.YYYY" }
            )
        }
    }
    rows {
        row {
            attributes(
                text {
                    fontFamily = "Times New Roman"
                    fontColor = Colors.BLACK
                    fontSize = 12
                },
                background { color = Colors.BLUE }
            )
        }
    }
}
----

<<<
== Advanced concepts

=== Merging rows.

When multiple `Row` model definitions are qualified by a predicate, they form a single synthetic row. Following rules regarding row merge applies:
- Row level attributes will be concatenated or merged if are of same type.
- Cell values will be concatenated, or overriden by last cell occurence at given column.
- Cell level attributes will be concatenated, or merged if of same type.
- Two attributes of same type are merged by overriding clashing attribute properties from left to right where on left side stands attribute from higher level (e.g. row level), and on right site stands attribute from lower level (e.g. cell level).

TBD.

<<<
=== Builder composition.

TBD.

<<<
== Cookbook recipes.

TBD.